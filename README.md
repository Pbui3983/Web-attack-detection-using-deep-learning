W# Web Attack Detection using Deep Learning

Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c xÃ¢y dá»±ng vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh **Há»c sÃ¢u (Deep Learning)** Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c cuá»™c táº¥n cÃ´ng Web. Há»‡ thá»‘ng sá»­ dá»¥ng cÃ¡c kiáº¿n trÃºc máº¡ng nÆ¡-ron tiÃªn tiáº¿n nhÆ° **CNN, LSTM, GRU, MLP** vÃ  mÃ´ hÃ¬nh lai **CNN-LSTM** Ä‘á»ƒ phÃ¢n loáº¡i cÃ¡c request Ä‘á»™c háº¡i dá»±a trÃªn bá»™ dá»¯ liá»‡u WEBIDS23.

## ğŸ“‚ Cáº¥u trÃºc Dá»± Ã¡n

Cáº¥u trÃºc thÆ° má»¥c Ä‘Æ°á»£c tá»• chá»©c module hÃ³a Ä‘á»ƒ dá»… quáº£n lÃ½:

```text
web-attack-detection/
â”œâ”€â”€ models/                           # Chá»©a cÃ¡c file mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n (.h5)
â”‚   â”œâ”€â”€ cnn_webids23_model.h5
â”‚   â”œâ”€â”€ lstm_webids23_model.h5
â”‚   â”œâ”€â”€ gru_webids23_model.h5
â”‚   â”œâ”€â”€ mlp_webids23_model.h5
â”‚   â””â”€â”€ cnn_lstm_webids23_model.h5
â”‚
â”œâ”€â”€ results/                          # Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ (Confusion Matrix, History)
â”‚   â”œâ”€â”€ *_confusion_matrix.png
â”‚   â””â”€â”€ *_train_history.png
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing-src/            # MÃ£ nguá»“n tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”‚   â”œâ”€â”€ preprocessed_data.ipynb
â”‚   â”‚   â””â”€â”€ preprocessed_data_2.ipynb
â”‚   â”‚
â”‚   â””â”€â”€ train-src/                    # MÃ£ nguá»“n huáº¥n luyá»‡n mÃ´ hÃ¬nh
â”‚       â”œâ”€â”€ train_cnn_balance.ipynb
â”‚       â”œâ”€â”€ train_lstm_balance.ipynb
â”‚       â”œâ”€â”€ train_gru_balance.ipynb
â”‚       â”œâ”€â”€ train_mlp_balance.ipynb
â”‚       â”œâ”€â”€ train_cnnlstm_balance.ipynb
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ requirements.txt                  # CÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
â””â”€â”€ README.md                         # TÃ i liá»‡u hÆ°á»›ng dáº«n
```
ğŸ§  MÃ´ hÃ¬nh & Giáº£i thuáº­t
Dá»± Ã¡n triá»ƒn khai vÃ  so sÃ¡nh hiá»‡u nÄƒng cá»§a 5 kiáº¿n trÃºc máº¡ng nÆ¡-ron khÃ¡c nhau. DÆ°á»›i Ä‘Ã¢y lÃ  chi tiáº¿t giáº£i thuáº­t vÃ  lÃ½ do sá»­ dá»¥ng:

1. Multi-Layer Perceptron (MLP)
Kiáº¿n trÃºc: Máº¡ng nÆ¡-ron truyá»n tháº³ng (Feed-forward) cÆ¡ báº£n vá»›i cÃ¡c lá»›p Dense.

Vai trÃ²: DÃ¹ng lÃ m baseline Ä‘á»ƒ so sÃ¡nh hiá»‡u nÄƒng vá»›i cÃ¡c mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n. PhÃ¹ há»£p vá»›i dá»¯ liá»‡u dáº¡ng báº£ng nhÆ°ng háº¡n cháº¿ trong viá»‡c báº¯t cÃ¡c Ä‘áº·c trÆ°ng chuá»—i hoáº·c khÃ´ng gian.

2. Convolutional Neural Networks (CNN)
Kiáº¿n trÃºc: Sá»­ dá»¥ng cÃ¡c lá»›p Conv1D Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng cá»¥c bá»™ (local features) tá»« cÃ¡c chuá»—i dá»¯ liá»‡u (vÃ­ dá»¥: cÃ¡c máº«u kÃ½ tá»± trong URL hoáº·c Payload).

Æ¯u Ä‘iá»ƒm: Hiá»‡u quáº£ trong viá»‡c phÃ¡t hiá»‡n cÃ¡c máº«u (patterns) cá»‘ Ä‘á»‹nh cá»§a cÃ¡c loáº¡i táº¥n cÃ´ng nhÆ° SQL Injection hay XSS.

3. Long Short-Term Memory (LSTM)
Kiáº¿n trÃºc: Máº¡ng nÆ¡-ron há»“i quy (RNN) cÃ³ kháº£ nÄƒng ghi nhá»› dÃ i háº¡n.

Æ¯u Ä‘iá»ƒm: Xá»­ lÃ½ tá»‘t dá»¯ liá»‡u dáº¡ng chuá»—i thá»i gian hoáº·c chuá»—i kÃ½ tá»±, giÃºp mÃ´ hÃ¬nh hiá»ƒu ngá»¯ cáº£nh cá»§a request trÆ°á»›c vÃ  sau, kháº¯c phá»¥c váº¥n Ä‘á» vanishing gradient cá»§a RNN thÆ°á»ng.

4. Gated Recurrent Unit (GRU)
Kiáº¿n trÃºc: Má»™t biáº¿n thá»ƒ Ä‘Æ¡n giáº£n hÃ³a cá»§a LSTM vá»›i Ã­t tham sá»‘ hÆ¡n.

Æ¯u Ä‘iá»ƒm: Tá»‘c Ä‘á»™ huáº¥n luyá»‡n nhanh hÆ¡n LSTM nhÆ°ng váº«n giá»¯ Ä‘Æ°á»£c kháº£ nÄƒng náº¯m báº¯t thÃ´ng tin chuá»—i tá»‘t.

5. Hybrid CNN-LSTM
Kiáº¿n trÃºc: Káº¿t há»£p Conv1D (Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng) vÃ  LSTM (Ä‘á»ƒ há»c sá»± phá»¥ thuá»™c chuá»—i).

CÆ¡ cháº¿: Dá»¯ liá»‡u Ä‘i qua CNN Ä‘á»ƒ lá»c nhiá»…u vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng quan trá»ng, sau Ä‘Ã³ output Ä‘Æ°á»£c Ä‘Æ°a vÃ o LSTM Ä‘á»ƒ phÃ¢n tÃ­ch ngá»¯ nghÄ©a theo thá»i gian. ÄÃ¢y thÆ°á»ng lÃ  mÃ´ hÃ¬nh cho Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t.

ğŸ›  YÃªu cáº§u cÃ i Ä‘áº·t
Äáº£m báº£o báº¡n Ä‘Ã£ cÃ i Ä‘áº·t Python (khuyÃªn dÃ¹ng 3.9 - 3.11).

Clone dá»± Ã¡n:

Bash

git clone https://github.com/Pbui3983/Web-attack-detection-using-deep-learning
cd web-attack-detection
CÃ i Ä‘áº·t thÆ° viá»‡n: Sá»­ dá»¥ng file requirements.txt Ä‘i kÃ¨m:

Bash

pip install -r requirements.txt
ğŸš€ HÆ°á»›ng dáº«n Sá»­ dá»¥ng & Chi tiáº¿t Code
Quy trÃ¬nh thá»±c hiá»‡n dá»± Ã¡n Ä‘i qua 3 bÆ°á»›c chÃ­nh, tÆ°Æ¡ng á»©ng vá»›i cÃ¡c thÆ° má»¥c trong src/:

BÆ°á»›c 1: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (src/preprocessing-src)
Sá»­ dá»¥ng preprocessed_data.ipynb.

Load Data: Äá»c dá»¯ liá»‡u thÃ´ (CSV).

Cleaning: Xá»­ lÃ½ giÃ¡ trá»‹ Null, Infinity.

Encoding: Chuyá»ƒn Ä‘á»•i nhÃ£n (Label Encoding) vÃ  cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n loáº¡i (One-Hot Encoding).

Scaling: Chuáº©n hÃ³a dá»¯ liá»‡u sá»‘ báº±ng MinMaxScaler Ä‘á»ƒ Ä‘Æ°a vá» khoáº£ng [0, 1] giÃºp mÃ´ hÃ¬nh há»™i tá»¥ nhanh hÆ¡n.

BÆ°á»›c 2: Huáº¥n luyá»‡n mÃ´ hÃ¬nh (src/train-src)
CÃ¡c file train_*_balance.ipynb thá»±c hiá»‡n quy trÃ¬nh huáº¥n luyá»‡n chuáº©n:

Reshape Data:

Vá»›i MLP: Input dáº¡ng 2D (samples, features).

Vá»›i CNN/LSTM/GRU: Input dáº¡ng 3D (samples, time_steps, features).

XÃ¢y dá»±ng Model (TensorFlow/Keras):

VÃ­ dá»¥ cáº¥u trÃºc CNN-LSTM trong code:

Python

model = Sequential()
model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X.shape[1], 1)))
model.add(MaxPooling1D(pool_size=2))
model.add(LSTM(64))
model.add(Dense(n_classes, activation='softmax'))
Compile & Fit: Sá»­ dá»¥ng Adam optimizer vÃ  sparse_categorical_crossentropy (hoáº·c categorical) loss function.

LÆ°u Model: Model tá»‘t nháº¥t Ä‘Æ°á»£c lÆ°u vÃ o thÆ° má»¥c models/.

BÆ°á»›c 3: ÄÃ¡nh giÃ¡ (results)
Code tá»± Ä‘á»™ng sinh ra cÃ¡c biá»ƒu Ä‘á»“ Ä‘Ã¡nh giÃ¡:

Confusion Matrix: Äá»ƒ xem Ä‘á»™ chÃ­nh xÃ¡c trÃªn tá»«ng loáº¡i táº¥n cÃ´ng cá»¥ thá»ƒ.

Accuracy/Loss History: Äá»ƒ kiá»ƒm tra hiá»‡n tÆ°á»£ng Overfitting/Underfitting.

ğŸ“Š Káº¿t quáº£ (Results)
CÃ¡c biá»ƒu Ä‘á»“ káº¿t quáº£ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c results/.

CNN-LSTM thÆ°á»ng cho káº¿t quáº£ tá»‘t nháº¥t nhá» kháº£ nÄƒng há»c Ä‘áº·c trÆ°ng há»—n há»£p.

MLP cÃ³ tá»‘c Ä‘á»™ train nhanh nháº¥t nhÆ°ng Ä‘á»™ chÃ­nh xÃ¡c tháº¥p hÆ¡n trÃªn cÃ¡c máº«u táº¥n cÃ´ng phá»©c táº¡p.

ğŸ‘¥ TÃ¡c giáº£
BÃ¹i Trá»ng PhÃºc